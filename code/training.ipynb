{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cd5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ardca import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0586c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_path = \"../data/PF00014_mgap6.fasta.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842444cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MSA data...\n",
      "MSA shape: (13600, 51)\n",
      "Effective sequences: 4208.5\n",
      "Sequence length: 51\n",
      "Alphabet size: 21\n",
      "Training ArDCA model...\n",
      "Epoch 0: Train Loss=519180.6250, Val Loss=133676.5625, Val Perplexity=2.6120\n",
      "Epoch 10: Train Loss=467445.9688, Val Loss=121072.3750, Val Perplexity=2.3794\n",
      "Epoch 20: Train Loss=425406.8125, Val Loss=111464.8750, Val Perplexity=2.2051\n",
      "Epoch 30: Train Loss=392916.5625, Val Loss=104553.0781, Val Perplexity=2.0793\n",
      "Epoch 40: Train Loss=369171.1250, Val Loss=99933.3984, Val Perplexity=1.9923\n",
      "Epoch 50: Train Loss=352290.9062, Val Loss=96985.7578, Val Perplexity=1.9328\n",
      "Epoch 60: Train Loss=340136.3125, Val Loss=95108.9609, Val Perplexity=1.8911\n",
      "Epoch 70: Train Loss=331051.0938, Val Loss=93882.1250, Val Perplexity=1.8608\n",
      "Epoch 80: Train Loss=323954.5625, Val Loss=93048.9375, Val Perplexity=1.8377\n",
      "Epoch 90: Train Loss=318192.2188, Val Loss=92463.0234, Val Perplexity=1.8193\n",
      "Evaluating model...\n",
      "Final train NLL: 0.5465\n",
      "Final val NLL: 0.5909\n",
      "Final val perplexity: 1.8055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ArDCA(),\n",
       " {'train_loss': [519180.625,\n",
       "   513588.5,\n",
       "   508084.40625,\n",
       "   502670.90625,\n",
       "   497350.09375,\n",
       "   492123.78125,\n",
       "   486993.28125,\n",
       "   481959.65625,\n",
       "   477023.6875,\n",
       "   472185.71875,\n",
       "   467445.96875,\n",
       "   462804.34375,\n",
       "   458260.625,\n",
       "   453814.78125,\n",
       "   449466.3125,\n",
       "   445215.03125,\n",
       "   441060.625,\n",
       "   437002.75,\n",
       "   433041.34375,\n",
       "   429176.0625,\n",
       "   425406.8125,\n",
       "   421733.34375,\n",
       "   418155.5,\n",
       "   414672.875,\n",
       "   411285.25,\n",
       "   407992.0625,\n",
       "   404792.71875,\n",
       "   401686.4375,\n",
       "   398672.375,\n",
       "   395749.5,\n",
       "   392916.5625,\n",
       "   390172.21875,\n",
       "   387514.9375,\n",
       "   384943.125,\n",
       "   382455.0,\n",
       "   380048.59375,\n",
       "   377722.0625,\n",
       "   375473.15625,\n",
       "   373299.875,\n",
       "   371200.0,\n",
       "   369171.125,\n",
       "   367211.09375,\n",
       "   365317.59375,\n",
       "   363488.3125,\n",
       "   361720.875,\n",
       "   360013.0625,\n",
       "   358362.59375,\n",
       "   356767.34375,\n",
       "   355225.0,\n",
       "   353733.5625,\n",
       "   352290.90625,\n",
       "   350894.96875,\n",
       "   349543.875,\n",
       "   348235.71875,\n",
       "   346968.6875,\n",
       "   345741.03125,\n",
       "   344551.0625,\n",
       "   343397.09375,\n",
       "   342277.65625,\n",
       "   341191.1875,\n",
       "   340136.3125,\n",
       "   339111.625,\n",
       "   338115.875,\n",
       "   337147.6875,\n",
       "   336205.96875,\n",
       "   335289.59375,\n",
       "   334397.40625,\n",
       "   333528.46875,\n",
       "   332681.65625,\n",
       "   331856.1875,\n",
       "   331051.09375,\n",
       "   330265.46875,\n",
       "   329498.625,\n",
       "   328749.78125,\n",
       "   328018.125,\n",
       "   327303.09375,\n",
       "   326603.90625,\n",
       "   325920.0625,\n",
       "   325250.9375,\n",
       "   324595.90625,\n",
       "   323954.5625,\n",
       "   323326.28125,\n",
       "   322710.75,\n",
       "   322107.375,\n",
       "   321515.75,\n",
       "   320935.5625,\n",
       "   320366.34375,\n",
       "   319807.75,\n",
       "   319259.40625,\n",
       "   318721.03125,\n",
       "   318192.21875,\n",
       "   317672.78125,\n",
       "   317162.3125,\n",
       "   316660.65625,\n",
       "   316167.40625,\n",
       "   315682.40625,\n",
       "   315205.4375,\n",
       "   314736.1875,\n",
       "   314274.46875,\n",
       "   313820.09375],\n",
       "  'train_nll': [518674.21875,\n",
       "   513096.8125,\n",
       "   507597.625,\n",
       "   502179.5625,\n",
       "   496845.0625,\n",
       "   491596.28125,\n",
       "   486434.9375,\n",
       "   481362.5,\n",
       "   476380.09375,\n",
       "   471488.5,\n",
       "   466688.3125,\n",
       "   461979.875,\n",
       "   457363.3125,\n",
       "   452839.0,\n",
       "   448406.75,\n",
       "   444066.75,\n",
       "   439819.0,\n",
       "   435663.5,\n",
       "   431600.5,\n",
       "   427629.9375,\n",
       "   423752.0,\n",
       "   419966.75,\n",
       "   416274.25,\n",
       "   412674.375,\n",
       "   409167.125,\n",
       "   405752.1875,\n",
       "   402429.1875,\n",
       "   399197.59375,\n",
       "   396056.6875,\n",
       "   393005.71875,\n",
       "   390043.625,\n",
       "   387169.1875,\n",
       "   384381.125,\n",
       "   381677.96875,\n",
       "   379058.09375,\n",
       "   376519.71875,\n",
       "   374061.125,\n",
       "   371680.21875,\n",
       "   369375.09375,\n",
       "   367143.6875,\n",
       "   364983.71875,\n",
       "   362893.09375,\n",
       "   360869.625,\n",
       "   358911.09375,\n",
       "   357015.21875,\n",
       "   355179.8125,\n",
       "   353402.71875,\n",
       "   351681.8125,\n",
       "   350014.90625,\n",
       "   348400.0,\n",
       "   346835.0,\n",
       "   345317.9375,\n",
       "   343846.90625,\n",
       "   342420.0625,\n",
       "   341035.625,\n",
       "   339691.8125,\n",
       "   338386.96875,\n",
       "   337119.4375,\n",
       "   335887.75,\n",
       "   334690.3125,\n",
       "   333525.78125,\n",
       "   332392.75,\n",
       "   331289.90625,\n",
       "   330215.9375,\n",
       "   329169.6875,\n",
       "   328150.03125,\n",
       "   327155.8125,\n",
       "   326186.03125,\n",
       "   325239.625,\n",
       "   324315.71875,\n",
       "   323413.375,\n",
       "   322531.65625,\n",
       "   321669.8125,\n",
       "   320827.09375,\n",
       "   320002.65625,\n",
       "   319195.875,\n",
       "   318406.0,\n",
       "   317632.5,\n",
       "   316874.6875,\n",
       "   316131.96875,\n",
       "   315403.875,\n",
       "   314689.8125,\n",
       "   313989.375,\n",
       "   313302.0,\n",
       "   312627.25,\n",
       "   311964.78125,\n",
       "   311314.09375,\n",
       "   310674.875,\n",
       "   310046.6875,\n",
       "   309429.25,\n",
       "   308822.125,\n",
       "   308225.125,\n",
       "   307637.8125,\n",
       "   307060.0,\n",
       "   306491.3125,\n",
       "   305931.5625,\n",
       "   305380.46875,\n",
       "   304837.75,\n",
       "   304303.21875,\n",
       "   303776.65625],\n",
       "  'val_loss': [133676.5625,\n",
       "   121072.375,\n",
       "   111464.875,\n",
       "   104553.078125,\n",
       "   99933.3984375,\n",
       "   96985.7578125,\n",
       "   95108.9609375,\n",
       "   93882.125,\n",
       "   93048.9375,\n",
       "   92463.0234375],\n",
       "  'val_nll': [133184.859375,\n",
       "   120247.90625,\n",
       "   109698.265625,\n",
       "   101550.0625,\n",
       "   95615.3984375,\n",
       "   91408.71875,\n",
       "   88390.078125,\n",
       "   86148.296875,\n",
       "   84412.453125,\n",
       "   83015.359375],\n",
       "  'val_perplexity': [2.6119537353515625,\n",
       "   2.379377841949463,\n",
       "   2.2051358222961426,\n",
       "   2.0793402194976807,\n",
       "   1.9922586679458618,\n",
       "   1.9327504634857178,\n",
       "   1.8911466598510742,\n",
       "   1.8608304262161255,\n",
       "   1.8376904726028442,\n",
       "   1.8192753791809082]},\n",
       " MSAData(seqs=array([[ 2, 10,  3, ...,  5,  7,  2],\n",
       "        [ 2, 11,  4, ...,  1, 16,  2],\n",
       "        [ 2,  9, 10, ...,  3, 15,  2],\n",
       "        ...,\n",
       "        [ 2, 10,  9, ..., 10,  1,  2],\n",
       "        [ 2, 17, 11, ...,  9,  8,  2],\n",
       "        [ 2,  8, 19, ..., 15, 15,  2]], shape=(13600, 51), dtype=int16), weights=array([0.03448276, 0.2       , 1.        , ..., 0.5       , 0.25      ,\n",
       "        0.04545455], shape=(13600,)), M_eff=4208.516778789079, L=51, q=21, identity_tresh=0.8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_training_pipeline(msa_path, lambda_h=1e-6, lambda_J=13-4, max_gap_fraction=1.0, identity_thresh=0.8, val_frac=0.2, max_iters=100, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1be183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arvenv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
